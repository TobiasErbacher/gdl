{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "887d797a43cb41dcaf1ac5b80ed98b5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0e8c885abadf48b5bfd0a7cb9acf09b6",
              "IPY_MODEL_8dd2e26e7c194df980cb2b92064345f0",
              "IPY_MODEL_401e794f805544f5891c315d5a6c4054"
            ],
            "layout": "IPY_MODEL_1ce5f239d34444d98c3883200fce3e32"
          }
        },
        "0e8c885abadf48b5bfd0a7cb9acf09b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2641b63114414e66abf26d294b1218d2",
            "placeholder": "​",
            "style": "IPY_MODEL_acd92c141a5c4b36908943877ffe4ae1",
            "value": " 10%"
          }
        },
        "8dd2e26e7c194df980cb2b92064345f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e3da2a2077f4830a8ccbf58c33c968c",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0e227c6aa6304de1b97e58c75666dffb",
            "value": 2
          }
        },
        "401e794f805544f5891c315d5a6c4054": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87c4622e2578446c98dd8dbd091c50a0",
            "placeholder": "​",
            "style": "IPY_MODEL_26204dd39e624d0a88a069f8bef7ec0e",
            "value": " 2/20 [04:26&lt;39:05, 130.29s/it]"
          }
        },
        "1ce5f239d34444d98c3883200fce3e32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2641b63114414e66abf26d294b1218d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acd92c141a5c4b36908943877ffe4ae1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e3da2a2077f4830a8ccbf58c33c968c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e227c6aa6304de1b97e58c75666dffb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "87c4622e2578446c98dd8dbd091c50a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26204dd39e624d0a88a069f8bef7ec0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Adaptive Propagation Graph Convolutional Network (AP-GCN)\n"
      ],
      "metadata": {
        "id": "fURupqzUL5_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(f\"Current PyTorch version: {torch.__version__}\")\n",
        "print(f\"Current CUDA version: {torch.version.cuda}\")\n",
        "\n",
        "!pip uninstall -y torch torchvision torchaudio\n",
        "# PyTorch 2.5.0 with CUDA 12.4\n",
        "!pip install torch==2.5.0+cu124 torchvision==0.20.0+cu124 torchaudio==2.5.0+cu124 --index-url https://download.pytorch.org/whl/cu124\n",
        "# now geometric stuff\n",
        "!pip install torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-2.5.0+cu124.html\n",
        "!pip install torch-geometric\n",
        "!pip install matplotlib seaborn PyYAML tqdm\n",
        "#need ro restart session"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PDtoRfqsL_Om",
        "outputId": "6a1e910c-7015-4ab9-dbde-af9376445b15"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current PyTorch version: 2.6.0+cu124\n",
            "Current CUDA version: 12.4\n",
            "Found existing installation: torch 2.6.0+cu124\n",
            "Uninstalling torch-2.6.0+cu124:\n",
            "  Successfully uninstalled torch-2.6.0+cu124\n",
            "Found existing installation: torchvision 0.21.0+cu124\n",
            "Uninstalling torchvision-0.21.0+cu124:\n",
            "  Successfully uninstalled torchvision-0.21.0+cu124\n",
            "Found existing installation: torchaudio 2.6.0+cu124\n",
            "Uninstalling torchaudio-2.6.0+cu124:\n",
            "  Successfully uninstalled torchaudio-2.6.0+cu124\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
            "Collecting torch==2.5.0+cu124\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torch-2.5.0%2Bcu124-cp311-cp311-linux_x86_64.whl (908.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m908.3/908.3 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.20.0+cu124\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torchvision-0.20.0%2Bcu124-cp311-cp311-linux_x86_64.whl (7.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.5.0+cu124\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torchaudio-2.5.0%2Bcu124-cp311-cp311-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0+cu124) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0+cu124) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0+cu124) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0+cu124) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0+cu124) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.5.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.5.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.5.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m89.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.5.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.5.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.5.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.5.147 (from torch==2.5.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.5.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.5.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0+cu124) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0+cu124) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.5.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.1.0 (from torch==2.5.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0+cu124) (1.13.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.20.0+cu124) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.20.0+cu124) (11.1.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.5.0+cu124) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.5.0+cu124) (3.0.2)\n",
            "Installing collected packages: triton, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torch-2.5.0+cu124 torchaudio-2.5.0+cu124 torchvision-0.20.0+cu124 triton-3.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchgen"
                ]
              },
              "id": "f9b531793f69428ca118fb10d22fe154"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.5.0+cu124.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu124/torch_scatter-2.1.2%2Bpt25cu124-cp311-cp311-linux_x86_64.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu124/torch_sparse-0.6.18%2Bpt25cu124-cp311-cp311-linux_x86_64.whl (5.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m102.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse) (1.14.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-sparse) (2.0.2)\n",
            "Installing collected packages: torch-scatter, torch-sparse\n",
            "Successfully installed torch-scatter-2.1.2+pt25cu124 torch-sparse-0.6.18+pt25cu124\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.13)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.1.31)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.6.1\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (6.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(f\"Current PyTorch version: {torch.__version__}\")\n",
        "print(f\"Current CUDA version: {torch.version.cuda}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_M0Fu1cNeZu",
        "outputId": "58b6f051-306b-4cca-98e6-e94d0b2eb3cc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current PyTorch version: 2.5.0+cu124\n",
            "Current CUDA version: 12.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric.transforms as T\n",
        "from torch.nn import ModuleList, Dropout, ReLU, Linear\n",
        "from torch_geometric.nn import GCNConv, MessagePassing\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.utils import dropout_adj, to_networkx, degree, remove_self_loops, dropout_edge\n",
        "from torch_geometric.utils import add_self_loops as add_self_loops_fn\n",
        "from torch_geometric.data import Data, InMemoryDataset\n",
        "from torch_sparse import SparseTensor, matmul, fill_diag, sum as sparse_sum, mul\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import networkx as nx\n",
        "from sklearn.decomposition import PCA\n",
        "from matplotlib.colors import LinearSegmentedColormap, Normalize\n",
        "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
        "from matplotlib.cm import ScalarMappable\n",
        "import os\n",
        "import time\n",
        "from typing import List\n",
        "\n",
        "# seed plus gpu setting.\n",
        "torch.manual_seed(4143496719)\n",
        "np.random.seed(4143496719)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-W8KlM3nMMbB",
        "outputId": "68366047-8ec8-479a-89e1-04ec3d05649b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "4La0-3gYNoeI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AdaptivePropagation(MessagePassing):\n",
        "    \"\"\"\n",
        "    Adaptive Propagation layer that allows each node to determine\n",
        "    its own optimal number of propagation steps.\n",
        "\n",
        "    This implements the core adaptive halting mechanism described in the paper.\n",
        "    \"\"\"\n",
        "    def __init__(self, niter: int, h_size: int, bias = True, **kwargs):\n",
        "        \"\"\"\n",
        "        Adaptive propagation layer.\n",
        "\n",
        "        where:\n",
        "            niter: max number of propagation steps (T in the paper)\n",
        "            h_size: size of the node embeddings\n",
        "            bias: if to add a bias in the halting unit\n",
        "        \"\"\"\n",
        "        super(AdaptivePropagation, self).__init__(aggr='add', **kwargs)\n",
        "\n",
        "        self.niter = niter\n",
        "        self.halt = Linear(h_size, 1) # halting unit (Q and q in equation 6)\n",
        "\n",
        "        self.reg_params = list(self.halt.parameters()) #halting params\n",
        "        self.dropout = Dropout()\n",
        "\n",
        "        # normalization params for the GCN layer norm they do in their code, needed to adapt for the new version.\n",
        "        self.improved = False\n",
        "        self.add_self_loops = True\n",
        "\n",
        "        # init params\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        \"\"\"\n",
        "        bias around 1/n+1 -> check my paper comments. it is easy to show that after passing\n",
        "        through the sigmoid, we get that the probability takes a value around 1/n+1\n",
        "        \"\"\"\n",
        "        self.halt.reset_parameters()\n",
        "\n",
        "        x = (self.niter+1) // 1\n",
        "        b = math.log((1/x)/(1-(1/x)))\n",
        "        self.halt.bias.data.fill_(b)\n",
        "\n",
        "    def forward(self, local_preds: torch.FloatTensor, edge_index):\n",
        "        \"\"\"\n",
        "        local_preds: node embeddings from local prediction network\n",
        "        edge_index: graph connectivity in COO format\n",
        "\n",
        "        returns:\n",
        "            Updated node embeddings, number of steps, and remainders\n",
        "        \"\"\"\n",
        "        sz = local_preds.size(0) #num of nodes.\n",
        "\n",
        "        steps = torch.ones(sz).to(local_preds.device)  # steps for each node (K_i)\n",
        "        sum_h = torch.zeros(sz).to(local_preds.device)  # accum halting probs\n",
        "        continue_mask = torch.ones(sz, dtype=torch.bool).to(local_preds.device)  # active nodes\n",
        "        x = torch.zeros_like(local_preds).to(local_preds.device)  # embeddings\n",
        "\n",
        "        # dropout of embedding.\n",
        "        prop = self.dropout(local_preds)\n",
        "\n",
        "        # propagation loop\n",
        "        for _ in range(self.niter):\n",
        "            old_prop = prop #h^(t-1)\n",
        "\n",
        "            continue_fmask = continue_mask.float().to(local_preds.device)\n",
        "            drop_edge_index, _ = dropout_edge(edge_index, p=0.5, training=self.training) #default is 0.5 as they did.\n",
        "\n",
        "            # GCN normalization using the util that is now available.  -> https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/conv/gcn_conv.html#GCNConv\n",
        "            edge_index_norm, norm = gcn_norm(\n",
        "                drop_edge_index, None,\n",
        "                sz, self.improved,\n",
        "                self.add_self_loops,\n",
        "                self.flow, local_preds.dtype\n",
        "            )\n",
        "\n",
        "            prop = self.propagate(edge_index_norm, x=prop, norm=norm)\n",
        "            h = torch.sigmoid(self.halt(prop)).t().squeeze() # h^k_i = σ(Qz^k_i + q)\n",
        "\n",
        "            # Handle dimension issues for single-node graphs\n",
        "            # if h.dim() == 0:\n",
        "            #     h = h.unsqueeze(0)\n",
        "\n",
        "            # here we do the soft update based on equation 7\n",
        "            # K_i = min{k : ∑(j=1 to k) h^j_i >= 1 - ε}\n",
        "            # 0.99 is equivalent to (1 - ε) where ε = 0.01\n",
        "            prob_mask = (((sum_h+h) < 0.99) & continue_mask).squeeze()\n",
        "            prob_fmask = prob_mask.float().to(local_preds.device)\n",
        "\n",
        "            # we add another step for those nodes that continue and that the accum prob is lower than threshold.\n",
        "            steps = steps + prob_fmask\n",
        "            sum_h = sum_h + prob_fmask * h #and update the accumulation for those nodes that continue  (otherwise the prob mask takes 0 so no update. )\n",
        "\n",
        "            final_iter = steps < self.niter\n",
        "\n",
        "            # if mask prob is 1 means that need to continue + did not reach the end so continue.\n",
        "            condition = prob_mask & final_iter\n",
        "            p = torch.where(condition, sum_h, 1-sum_h) #p^k_i according to equation 8\n",
        "\n",
        "            # this is something they did in the code too.\n",
        "            to_update = self.dropout(continue_fmask).unsqueeze(1)\n",
        "\n",
        "            # equation 9 -> softupdate.\n",
        "            # z̃_i = (1/K_i) * ∑(k=1 to K_i) p^k_i * z^k_i + (1-p^k_i) * z^(k-1)_i\n",
        "            x = x + (prop * p.unsqueeze(1) + old_prop * (1-p).unsqueeze(1)) * to_update\n",
        "            continue_mask = continue_mask & prob_mask\n",
        "\n",
        "            # if all nodes halted, then stop.\n",
        "            if (~continue_mask).all():\n",
        "                break\n",
        "\n",
        "        # continueation of the equation 9 (1/K_i)\n",
        "        x = x / steps.unsqueeze(1)\n",
        "\n",
        "        # updated embeddings, steps, and  R_i\n",
        "        return x, steps, (1-sum_h)\n",
        "\n",
        "    def message(self, x_j, norm):\n",
        "        return norm.view(-1, 1) * x_j\n",
        "\n",
        "class APGCN(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    The actual Adaptive Propagation Graph Convolutional Network.\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 dataset,\n",
        "                 niter=10,\n",
        "                 prop_penalty=0.005,\n",
        "                 hidden=[64],\n",
        "                 dropout=0.5):\n",
        "        \"\"\"\n",
        "        dataset: graph dataset\n",
        "        niter: max number of propagation steps\n",
        "        prop_penalty: prop penalty α in equation 11\n",
        "        hidden: list of hidden layer sizes\n",
        "        dropout: dropout rate\n",
        "        \"\"\"\n",
        "        super(APGCN, self).__init__()\n",
        "\n",
        "        num_features = [dataset.data.x.shape[1]] + hidden + [dataset.num_classes] # layer sizes.\n",
        "\n",
        "        # as authors did, we create the mlp before prop.\n",
        "        layers = []\n",
        "        for in_features, out_features in zip(num_features[:-1], num_features[1:]):\n",
        "            layers.append(Linear(in_features, out_features))\n",
        "\n",
        "        # we do the propagation with the previous format.\n",
        "        self.prop = AdaptivePropagation(niter, dataset.num_classes)\n",
        "\n",
        "        self.prop_penalty = prop_penalty # alpha\n",
        "\n",
        "        self.layers = ModuleList(layers) #mlp\n",
        "\n",
        "        # we separate parameters into regularized and non-regularized groups -> they did this in their code.\n",
        "        self.reg_params = list(layers[0].parameters())\n",
        "        self.non_reg_params = list([p for l in layers[1:] for p in l.parameters()])\n",
        "        self.dropout = Dropout(p=dropout)\n",
        "        self.act_fn = ReLU()\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.prop.reset_parameters()\n",
        "        for layer in self.layers:\n",
        "            layer.reset_parameters()\n",
        "\n",
        "    def forward(self, data, return_propagation_cost=False):\n",
        "        \"\"\"\n",
        "        data: PyG data object containing x and edge_index\n",
        "        return_propagation_cost: Whether to return the propagation cost\n",
        "\n",
        "        returns:\n",
        "            Log probabilities, number of steps, and remainders\n",
        "        \"\"\"\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        # MLP\n",
        "        for i, layer in enumerate(self.layers):\n",
        "            x = layer(self.dropout(x))\n",
        "\n",
        "            #no non linearity in the last layer.\n",
        "            if i == len(self.layers) - 1:\n",
        "                break\n",
        "\n",
        "            x = self.act_fn(x)\n",
        "\n",
        "        # the adaptive propagation.\n",
        "        x, steps, reminders = self.prop(x, edge_index)\n",
        "\n",
        "        # log probabilities, steps, and remainders\n",
        "        if return_propagation_cost:\n",
        "            return torch.nn.functional.log_softmax(x, dim=1), steps, reminders\n",
        "        return torch.nn.functional.log_softmax(x, dim=1), steps, reminders"
      ],
      "metadata": {
        "id": "axHHDKWSNjk3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seeds Authors:"
      ],
      "metadata": {
        "id": "Tpr6bamBOAHP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def gen_seeds(size: int = None) -> np.ndarray:\n",
        "    max_uint32 = np.iinfo(np.uint32).max\n",
        "    return np.random.randint(\n",
        "            max_uint32+1, size=size, dtype=np.uint32)\n",
        "\n",
        "quick_seeds = [2144199730, 794209841]\n",
        "\n",
        "test_seeds = [2144199730, 794209841, 2985733717, 2282690970, 1901557222,\n",
        "        2009332812, 2266730407, 635625077, 3538425002, 960893189,\n",
        "        497096336, 3940842554, 3594628340, 948012117, 3305901371,\n",
        "        3644534211, 2297033685, 4092258879, 2590091101, 1694925034]\n",
        "\n",
        "development_seed = 4143496719\n"
      ],
      "metadata": {
        "id": "nog-jk3EOBq6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Management Authors:"
      ],
      "metadata": {
        "id": "c3mPLY-POMJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "from typing import Dict, Union, Tuple, Any\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "\n",
        "__all__ = ['SparseGraph']\n",
        "\n",
        "sparse_graph_properties = [\n",
        "        'adj_matrix', 'attr_matrix', 'labels',\n",
        "        'node_names', 'attr_names', 'class_names',\n",
        "        'metadata']\n",
        "\n",
        "\n",
        "class SparseGraph:\n",
        "    \"\"\"Attributed labeled graph stored in sparse matrix form.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    adj_matrix\n",
        "        Adjacency matrix in CSR format. Shape [num_nodes, num_nodes]\n",
        "    attr_matrix\n",
        "        Attribute matrix in CSR or numpy format. Shape [num_nodes, num_attr]\n",
        "    labels\n",
        "        Array, where each entry represents respective node's label(s). Shape [num_nodes]\n",
        "        Alternatively, CSR matrix with labels in one-hot format. Shape [num_nodes, num_classes]\n",
        "    node_names\n",
        "        Names of nodes (as strings). Shape [num_nodes]\n",
        "    attr_names\n",
        "        Names of the attributes (as strings). Shape [num_attr]\n",
        "    class_names\n",
        "        Names of the class labels (as strings). Shape [num_classes]\n",
        "    metadata\n",
        "        Additional metadata such as text.\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self, adj_matrix: sp.spmatrix,\n",
        "            attr_matrix: Union[np.ndarray, sp.spmatrix] = None,\n",
        "            labels: Union[np.ndarray, sp.spmatrix] = None,\n",
        "            node_names: np.ndarray = None,\n",
        "            attr_names: np.ndarray = None,\n",
        "            class_names: np.ndarray = None,\n",
        "            metadata: Any = None):\n",
        "        # Make sure that the dimensions of matrices / arrays all agree\n",
        "        if sp.isspmatrix(adj_matrix):\n",
        "            adj_matrix = adj_matrix.tocsr().astype(np.float32)\n",
        "        else:\n",
        "            raise ValueError(\"Adjacency matrix must be in sparse format (got {0} instead).\"\n",
        "                             .format(type(adj_matrix)))\n",
        "\n",
        "        if adj_matrix.shape[0] != adj_matrix.shape[1]:\n",
        "            raise ValueError(\"Dimensions of the adjacency matrix don't agree.\")\n",
        "\n",
        "        if attr_matrix is not None:\n",
        "            if sp.isspmatrix(attr_matrix):\n",
        "                attr_matrix = attr_matrix.tocsr().astype(np.float32)\n",
        "            elif isinstance(attr_matrix, np.ndarray):\n",
        "                attr_matrix = attr_matrix.astype(np.float32)\n",
        "            else:\n",
        "                raise ValueError(\"Attribute matrix must be a sp.spmatrix or a np.ndarray (got {0} instead).\"\n",
        "                                 .format(type(attr_matrix)))\n",
        "\n",
        "            if attr_matrix.shape[0] != adj_matrix.shape[0]:\n",
        "                raise ValueError(\"Dimensions of the adjacency and attribute matrices don't agree.\")\n",
        "\n",
        "        if labels is not None:\n",
        "            if labels.shape[0] != adj_matrix.shape[0]:\n",
        "                raise ValueError(\"Dimensions of the adjacency matrix and the label vector don't agree.\")\n",
        "\n",
        "        if node_names is not None:\n",
        "            if len(node_names) != adj_matrix.shape[0]:\n",
        "                raise ValueError(\"Dimensions of the adjacency matrix and the node names don't agree.\")\n",
        "\n",
        "        if attr_names is not None:\n",
        "            if len(attr_names) != attr_matrix.shape[1]:\n",
        "                raise ValueError(\"Dimensions of the attribute matrix and the attribute names don't agree.\")\n",
        "\n",
        "        self.adj_matrix = adj_matrix\n",
        "        self.attr_matrix = attr_matrix\n",
        "        self.labels = labels\n",
        "        self.node_names = node_names\n",
        "        self.attr_names = attr_names\n",
        "        self.class_names = class_names\n",
        "        self.metadata = metadata\n",
        "\n",
        "    def num_nodes(self) -> int:\n",
        "        \"\"\"Get the number of nodes in the graph.\n",
        "        \"\"\"\n",
        "        return self.adj_matrix.shape[0]\n",
        "\n",
        "    def num_edges(self) -> int:\n",
        "        \"\"\"Get the number of edges in the graph.\n",
        "\n",
        "        For undirected graphs, (i, j) and (j, i) are counted as _two_ edges.\n",
        "\n",
        "        \"\"\"\n",
        "        return self.adj_matrix.nnz\n",
        "\n",
        "    def get_neighbors(self, idx: int) -> np.ndarray:\n",
        "        \"\"\"Get the indices of neighbors of a given node.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        idx\n",
        "            Index of the node whose neighbors are of interest.\n",
        "\n",
        "        \"\"\"\n",
        "        return self.adj_matrix[idx].indices\n",
        "\n",
        "    def get_edgeid_to_idx_array(self) -> np.ndarray:\n",
        "        \"\"\"Return a Numpy Array that maps edgeids to the indices in the adjacency matrix.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        np.ndarray\n",
        "            The i'th entry contains the x- and y-coordinates of edge i in the adjacency matrix.\n",
        "            Shape [num_edges, 2]\n",
        "\n",
        "        \"\"\"\n",
        "        return np.transpose(self.adj_matrix.nonzero())\n",
        "\n",
        "    def is_directed(self) -> bool:\n",
        "        \"\"\"Check if the graph is directed (adjacency matrix is not symmetric).\n",
        "        \"\"\"\n",
        "        return (self.adj_matrix != self.adj_matrix.T).sum() != 0\n",
        "\n",
        "    def to_undirected(self) -> 'SparseGraph':\n",
        "        \"\"\"Convert to an undirected graph (make adjacency matrix symmetric).\n",
        "        \"\"\"\n",
        "        idx = self.get_edgeid_to_idx_array().T\n",
        "        ridx = np.ravel_multi_index(idx, self.adj_matrix.shape)\n",
        "        ridx_rev = np.ravel_multi_index(idx[::-1], self.adj_matrix.shape)\n",
        "\n",
        "        # Get duplicate edges (self-loops and opposing edges)\n",
        "        dup_ridx = ridx[np.isin(ridx, ridx_rev)]\n",
        "        dup_idx = np.unravel_index(dup_ridx, self.adj_matrix.shape)\n",
        "\n",
        "        # Check if the adjacency matrix weights are symmetric (if nonzero)\n",
        "        if len(dup_ridx) > 0 and not np.allclose(self.adj_matrix[dup_idx], self.adj_matrix[dup_idx[::-1]]):\n",
        "            raise ValueError(\"Adjacency matrix weights of opposing edges differ.\")\n",
        "\n",
        "        # Create symmetric matrix\n",
        "        new_adj_matrix = self.adj_matrix + self.adj_matrix.T\n",
        "        if len(dup_ridx) > 0:\n",
        "            new_adj_matrix[dup_idx] = (new_adj_matrix[dup_idx] - self.adj_matrix[dup_idx]).A1\n",
        "\n",
        "        self.adj_matrix = new_adj_matrix\n",
        "        return self\n",
        "\n",
        "    def is_weighted(self) -> bool:\n",
        "        \"\"\"Check if the graph is weighted (edge weights other than 1).\n",
        "        \"\"\"\n",
        "        return np.any(np.unique(self.adj_matrix[self.adj_matrix.nonzero()].A1) != 1)\n",
        "\n",
        "    def to_unweighted(self) -> 'SparseGraph':\n",
        "        \"\"\"Convert to an unweighted graph (set all edge weights to 1).\n",
        "        \"\"\"\n",
        "        self.adj_matrix.data = np.ones_like(self.adj_matrix.data)\n",
        "        return self\n",
        "\n",
        "    def is_connected(self) -> bool:\n",
        "        \"\"\"Check if the graph is connected.\n",
        "        \"\"\"\n",
        "        return sp.csgraph.connected_components(self.adj_matrix, return_labels=False) == 1\n",
        "\n",
        "    def has_self_loops(self) -> bool:\n",
        "        \"\"\"Check if the graph has self-loops.\n",
        "        \"\"\"\n",
        "        return not np.allclose(self.adj_matrix.diagonal(), 0)\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        props = []\n",
        "        for prop_name in sparse_graph_properties:\n",
        "            prop = getattr(self, prop_name)\n",
        "            if prop is not None:\n",
        "                if prop_name == 'metadata':\n",
        "                    props.append(prop_name)\n",
        "                else:\n",
        "                    shape_string = 'x'.join([str(x) for x in prop.shape])\n",
        "                    props.append(\"{} ({})\".format(prop_name, shape_string))\n",
        "        dir_string = 'Directed' if self.is_directed() else 'Undirected'\n",
        "        weight_string = 'weighted' if self.is_weighted() else 'unweighted'\n",
        "        conn_string = 'connected' if self.is_connected() else 'disconnected'\n",
        "        loop_string = 'has self-loops' if self.has_self_loops() else 'no self-loops'\n",
        "        return (\"<{}, {} and {} SparseGraph with {} edges ({}). Data: {}>\"\n",
        "                .format(dir_string, weight_string, conn_string,\n",
        "                        self.num_edges(), loop_string,\n",
        "                        ', '.join(props)))\n",
        "\n",
        "    # Quality of life (shortcuts)\n",
        "    def standardize(\n",
        "            self, make_unweighted: bool = True,\n",
        "            make_undirected: bool = True,\n",
        "            no_self_loops: bool = True,\n",
        "            select_lcc: bool = True\n",
        "            ) -> 'SparseGraph':\n",
        "        \"\"\"Perform common preprocessing steps: remove self-loops, make unweighted/undirected, select LCC.\n",
        "\n",
        "        All changes are done inplace.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        make_unweighted\n",
        "            Whether to set all edge weights to 1.\n",
        "        make_undirected\n",
        "            Whether to make the adjacency matrix symmetric. Can only be used if make_unweighted is True.\n",
        "        no_self_loops\n",
        "            Whether to remove self loops.\n",
        "        select_lcc\n",
        "            Whether to select the largest connected component of the graph.\n",
        "\n",
        "        \"\"\"\n",
        "        G = self\n",
        "        if make_unweighted and G.is_weighted():\n",
        "            G = G.to_unweighted()\n",
        "        if make_undirected and G.is_directed():\n",
        "            G = G.to_undirected()\n",
        "        if no_self_loops and G.has_self_loops():\n",
        "            G = remove_self_loops(G)\n",
        "        if select_lcc and not G.is_connected():\n",
        "            G = largest_connected_components(G, 1)\n",
        "        return G\n",
        "\n",
        "    def unpack(self) -> Tuple[sp.csr_matrix,\n",
        "                              Union[np.ndarray, sp.csr_matrix],\n",
        "                              Union[np.ndarray, sp.csr_matrix]]:\n",
        "        \"\"\"Return the (A, X, E, z) quadruplet.\n",
        "        \"\"\"\n",
        "        return self.adj_matrix, self.attr_matrix, self.labels\n",
        "\n",
        "    def to_flat_dict(self) -> Dict[str, Any]:\n",
        "        \"\"\"Return flat dictionary containing all SparseGraph properties.\n",
        "        \"\"\"\n",
        "        data_dict = {}\n",
        "        for key in sparse_graph_properties:\n",
        "            val = getattr(self, key)\n",
        "            if sp.isspmatrix(val):\n",
        "                data_dict['{}.data'.format(key)] = val.data\n",
        "                data_dict['{}.indices'.format(key)] = val.indices\n",
        "                data_dict['{}.indptr'.format(key)] = val.indptr\n",
        "                data_dict['{}.shape'.format(key)] = val.shape\n",
        "            else:\n",
        "                data_dict[key] = val\n",
        "        return data_dict\n",
        "\n",
        "    @staticmethod\n",
        "    def from_flat_dict(data_dict: Dict[str, Any]) -> 'SparseGraph':\n",
        "        \"\"\"Initialize SparseGraph from a flat dictionary.\n",
        "        \"\"\"\n",
        "        init_dict = {}\n",
        "        del_entries = []\n",
        "\n",
        "        # Construct sparse matrices\n",
        "        for key in data_dict.keys():\n",
        "            if key.endswith('_data') or key.endswith('.data'):\n",
        "                if key.endswith('_data'):\n",
        "                    sep = '_'\n",
        "                    warnings.warn(\n",
        "                            \"The separator used for sparse matrices during export (for .npz files) \"\n",
        "                            \"is now '.' instead of '_'. Please update (re-save) your stored graphs.\",\n",
        "                            DeprecationWarning, stacklevel=2)\n",
        "                else:\n",
        "                    sep = '.'\n",
        "                matrix_name = key[:-5]\n",
        "                mat_data = key\n",
        "                mat_indices = '{}{}indices'.format(matrix_name, sep)\n",
        "                mat_indptr = '{}{}indptr'.format(matrix_name, sep)\n",
        "                mat_shape = '{}{}shape'.format(matrix_name, sep)\n",
        "                if matrix_name == 'adj' or matrix_name == 'attr':\n",
        "                    warnings.warn(\n",
        "                            \"Matrices are exported (for .npz files) with full names now. \"\n",
        "                            \"Please update (re-save) your stored graphs.\",\n",
        "                            DeprecationWarning, stacklevel=2)\n",
        "                    matrix_name += '_matrix'\n",
        "                init_dict[matrix_name] = sp.csr_matrix(\n",
        "                        (data_dict[mat_data],\n",
        "                         data_dict[mat_indices],\n",
        "                         data_dict[mat_indptr]),\n",
        "                        shape=data_dict[mat_shape])\n",
        "                del_entries.extend([mat_data, mat_indices, mat_indptr, mat_shape])\n",
        "\n",
        "        # Delete sparse matrix entries\n",
        "        for del_entry in del_entries:\n",
        "            del data_dict[del_entry]\n",
        "\n",
        "        # Load everything else\n",
        "        for key, val in data_dict.items():\n",
        "            if ((val is not None) and (None not in val)):\n",
        "                init_dict[key] = val\n",
        "\n",
        "        # Check if the dictionary contains only entries in sparse_graph_properties\n",
        "        unknown_keys = [key for key in init_dict.keys() if key not in sparse_graph_properties]\n",
        "        if len(unknown_keys) > 0:\n",
        "            raise ValueError(\"Input dictionary contains keys that are not SparseGraph properties ({}).\"\n",
        "                             .format(unknown_keys))\n",
        "\n",
        "        return SparseGraph(**init_dict)\n",
        "\n",
        "\n",
        "def create_subgraph(\n",
        "        sparse_graph: SparseGraph,\n",
        "        _sentinel: None = None,\n",
        "        nodes_to_remove: np.ndarray = None,\n",
        "        nodes_to_keep: np.ndarray = None\n",
        "        ) -> SparseGraph:\n",
        "    \"\"\"Create a graph with the specified subset of nodes.\n",
        "\n",
        "    Exactly one of (nodes_to_remove, nodes_to_keep) should be provided, while the other stays None.\n",
        "    Note that to avoid confusion, it is required to pass node indices as named arguments to this function.\n",
        "\n",
        "    The subgraph partially points to the old graph's data.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    sparse_graph\n",
        "        Input graph.\n",
        "    _sentinel\n",
        "        Internal, to prevent passing positional arguments. Do not use.\n",
        "    nodes_to_remove\n",
        "        Indices of nodes that have to removed.\n",
        "    nodes_to_keep\n",
        "        Indices of nodes that have to be kept.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    SparseGraph\n",
        "        Graph with specified nodes removed.\n",
        "\n",
        "    \"\"\"\n",
        "    # Check that arguments are passed correctly\n",
        "    if _sentinel is not None:\n",
        "        raise ValueError(\"Only call `create_subgraph` with named arguments',\"\n",
        "                         \" (nodes_to_remove=...) or (nodes_to_keep=...).\")\n",
        "    if nodes_to_remove is None and nodes_to_keep is None:\n",
        "        raise ValueError(\"Either nodes_to_remove or nodes_to_keep must be provided.\")\n",
        "    elif nodes_to_remove is not None and nodes_to_keep is not None:\n",
        "        raise ValueError(\"Only one of nodes_to_remove or nodes_to_keep must be provided.\")\n",
        "    elif nodes_to_remove is not None:\n",
        "        nodes_to_keep = [i for i in range(sparse_graph.num_nodes()) if i not in nodes_to_remove]\n",
        "    elif nodes_to_keep is not None:\n",
        "        nodes_to_keep = sorted(nodes_to_keep)\n",
        "    else:\n",
        "        raise RuntimeError(\"This should never happen.\")\n",
        "\n",
        "    sparse_graph.adj_matrix = sparse_graph.adj_matrix[nodes_to_keep][:, nodes_to_keep]\n",
        "    if sparse_graph.attr_matrix is not None:\n",
        "        sparse_graph.attr_matrix = sparse_graph.attr_matrix[nodes_to_keep]\n",
        "    if sparse_graph.labels is not None:\n",
        "        sparse_graph.labels = sparse_graph.labels[nodes_to_keep]\n",
        "    if sparse_graph.node_names is not None:\n",
        "        sparse_graph.node_names = sparse_graph.node_names[nodes_to_keep]\n",
        "    return sparse_graph\n",
        "\n",
        "\n",
        "def largest_connected_components(sparse_graph: SparseGraph, n_components: int = 1) -> SparseGraph:\n",
        "    \"\"\"Select the largest connected components in the graph.\n",
        "\n",
        "    Changes are returned in a partially new SparseGraph.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    sparse_graph\n",
        "        Input graph.\n",
        "    n_components\n",
        "        Number of largest connected components to keep.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    SparseGraph\n",
        "        Subgraph of the input graph where only the nodes in largest n_components are kept.\n",
        "\n",
        "    \"\"\"\n",
        "    _, component_indices = sp.csgraph.connected_components(sparse_graph.adj_matrix)\n",
        "    component_sizes = np.bincount(component_indices)\n",
        "    components_to_keep = np.argsort(component_sizes)[::-1][:n_components]  # reverse order to sort descending\n",
        "    nodes_to_keep = [\n",
        "        idx for (idx, component) in enumerate(component_indices) if component in components_to_keep\n",
        "    ]\n",
        "    return create_subgraph(sparse_graph, nodes_to_keep=nodes_to_keep)\n",
        "\n",
        "\n",
        "def remove_self_loops(sparse_graph: SparseGraph) -> SparseGraph:\n",
        "    \"\"\"Remove self loops (diagonal entries in the adjacency matrix).\n",
        "\n",
        "    Changes are returned in a partially new SparseGraph.\n",
        "\n",
        "    \"\"\"\n",
        "    num_self_loops = (~np.isclose(sparse_graph.adj_matrix.diagonal(), 0)).sum()\n",
        "    if num_self_loops > 0:\n",
        "        sparse_graph.adj_matrix = sparse_graph.adj_matrix.tolil()\n",
        "        sparse_graph.adj_matrix.setdiag(0)\n",
        "        sparse_graph.adj_matrix = sparse_graph.adj_matrix.tocsr()\n",
        "        warnings.warn(\"{0} self loops removed\".format(num_self_loops))\n",
        "\n",
        "    return sparse_graph\n"
      ],
      "metadata": {
        "id": "QKwUVCvuOZN9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numbers import Number\n",
        "from typing import Union\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "from os.path import join\n",
        "\n",
        "data_dir = os.path.join(os.getcwd(), \"data\")\n",
        "\n",
        "def load_from_npz(file_name: str) -> SparseGraph:\n",
        "    \"\"\"Load a SparseGraph from a Numpy binary file.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    file_name\n",
        "        Name of the file to load.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    SparseGraph\n",
        "        Graph in sparse matrix format.\n",
        "\n",
        "    \"\"\"\n",
        "    with np.load(file_name, allow_pickle=True) as loader:\n",
        "        loader = dict(loader)\n",
        "        dataset = SparseGraph.from_flat_dict(loader)\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def load_dataset(name: str,\n",
        "                 directory: Union[Path, str] = data_dir\n",
        "                 ) -> SparseGraph:\n",
        "    \"\"\"Load a dataset.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    name\n",
        "        Name of the dataset to load.\n",
        "    directory\n",
        "        Path to the directory where the datasets are stored.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    SparseGraph\n",
        "        The requested dataset in sparse format.\n",
        "\n",
        "    \"\"\"\n",
        "    if isinstance(directory, str):\n",
        "        directory = Path(directory)\n",
        "    if not name.endswith('.npz'):\n",
        "        name += '.npz'\n",
        "    path_to_file = directory / name\n",
        "    if path_to_file.exists():\n",
        "        return load_from_npz(path_to_file)\n",
        "    else:\n",
        "        raise ValueError(\"{} doesn't exist.\".format(path_to_file))\n",
        "\n",
        "\n",
        "def networkx_to_sparsegraph(\n",
        "        nx_graph: Union['nx.Graph', 'nx.DiGraph'],\n",
        "        label_name: str = None,\n",
        "        sparse_node_attrs: bool = True,\n",
        "        sparse_edge_attrs: bool = True\n",
        "        ) -> 'SparseGraph':\n",
        "    \"\"\"Convert NetworkX graph to SparseGraph.\n",
        "\n",
        "    Node attributes need to be numeric.\n",
        "    Missing entries are interpreted as 0.\n",
        "    Labels can be any object. If non-numeric they are interpreted as\n",
        "    categorical and enumerated.\n",
        "\n",
        "    This ignores all edge attributes except the edge weights.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    nx_graph\n",
        "        Graph to convert.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    SparseGraph\n",
        "        Converted graph.\n",
        "\n",
        "    \"\"\"\n",
        "    import networkx as nx\n",
        "\n",
        "    # Extract node names\n",
        "    int_names = True\n",
        "    for node in nx_graph.nodes:\n",
        "        int_names &= isinstance(node, int)\n",
        "    if int_names:\n",
        "        node_names = None\n",
        "    else:\n",
        "        node_names = np.array(nx_graph.nodes)\n",
        "        nx_graph = nx.convert_node_labels_to_integers(nx_graph)\n",
        "\n",
        "    # Extract adjacency matrix\n",
        "    adj_matrix = nx.adjacency_matrix(nx_graph)\n",
        "\n",
        "    # Collect all node attribute names\n",
        "    attrs = set()\n",
        "    for _, node_data in nx_graph.nodes().data():\n",
        "        attrs.update(node_data.keys())\n",
        "\n",
        "    # Initialize labels and remove them from the attribute names\n",
        "    if label_name is None:\n",
        "        labels = None\n",
        "    else:\n",
        "        if label_name not in attrs:\n",
        "            raise ValueError(\"No attribute with label name '{}' found.\".format(label_name))\n",
        "        attrs.remove(label_name)\n",
        "        labels = [0 for _ in range(nx_graph.number_of_nodes())]\n",
        "\n",
        "    if len(attrs) > 0:\n",
        "        # Save attribute names if not integer\n",
        "        all_integer = all((isinstance(attr, int) for attr in attrs))\n",
        "        if all_integer:\n",
        "            attr_names = None\n",
        "            attr_mapping = None\n",
        "        else:\n",
        "            attr_names = np.array(list(attrs))\n",
        "            attr_mapping = {k: i for i, k in enumerate(attr_names)}\n",
        "\n",
        "        # Initialize attribute matrix\n",
        "        if sparse_node_attrs:\n",
        "            attr_matrix = sp.lil_matrix((nx_graph.number_of_nodes(), len(attr_names)), dtype=np.float32)\n",
        "        else:\n",
        "            attr_matrix = np.zeros((nx_graph.number_of_nodes(), len(attr_names)), dtype=np.float32)\n",
        "    else:\n",
        "        attr_matrix = None\n",
        "        attr_names = None\n",
        "\n",
        "    # Fill label and attribute matrices\n",
        "    for inode, node_attrs in nx_graph.nodes.data():\n",
        "        for key, val in node_attrs.items():\n",
        "            if key == label_name:\n",
        "                labels[inode] = val\n",
        "            else:\n",
        "                if not isinstance(val, Number):\n",
        "                    if node_names is None:\n",
        "                        raise ValueError(\"Node {} has attribute '{}' with value '{}', which is not a number.\"\n",
        "                                         .format(inode, key, val))\n",
        "                    else:\n",
        "                        raise ValueError(\"Node '{}' has attribute '{}' with value '{}', which is not a number.\"\n",
        "                                         .format(node_names[inode], key, val))\n",
        "                if attr_mapping is None:\n",
        "                    attr_matrix[inode, key] = val\n",
        "                else:\n",
        "                    attr_matrix[inode, attr_mapping[key]] = val\n",
        "    if attr_matrix is not None and sparse_node_attrs:\n",
        "        attr_matrix = attr_matrix.tocsr()\n",
        "\n",
        "    # Convert labels to integers\n",
        "    if labels is None:\n",
        "        class_names = None\n",
        "    else:\n",
        "        try:\n",
        "            labels = np.array(labels, dtype=np.float32)\n",
        "            class_names = None\n",
        "        except ValueError:\n",
        "            class_names = np.unique(labels)\n",
        "            class_mapping = {k: i for i, k in enumerate(class_names)}\n",
        "            labels_int = np.empty(nx_graph.number_of_nodes(), dtype=np.float32)\n",
        "            for inode, label in enumerate(labels):\n",
        "                labels_int[inode] = class_mapping[label]\n",
        "            labels = labels_int\n",
        "\n",
        "    return SparseGraph(\n",
        "            adj_matrix=adj_matrix, attr_matrix=attr_matrix, labels=labels,\n",
        "            node_names=node_names, attr_names=attr_names, class_names=class_names,\n",
        "            metadata=None)\n"
      ],
      "metadata": {
        "id": "SL2MFKO7OUu_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "__author__ = \"Stefan Weißenberger and Johannes Klicpera\"\n",
        "__license__ = \"MIT\"\n",
        "\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "from scipy.linalg import expm\n",
        "\n",
        "import torch\n",
        "from torch_geometric.data import Data, InMemoryDataset\n",
        "from torch_geometric.datasets import Planetoid, Amazon, Coauthor\n",
        "import scipy.sparse as sp\n",
        "import scipy.sparse.linalg as spla\n",
        "\n",
        "DATA_PATH = 'data'\n",
        "\n",
        "def normalize_attributes(attr_matrix):\n",
        "    epsilon = 1e-12\n",
        "    if isinstance(attr_matrix, sp.csr_matrix):\n",
        "        attr_norms = spla.norm(attr_matrix, ord=1, axis=1)\n",
        "        attr_invnorms = 1 / np.maximum(attr_norms, epsilon)\n",
        "        attr_mat_norm = attr_matrix.multiply(attr_invnorms[:, np.newaxis])\n",
        "    else:\n",
        "        attr_norms = np.linalg.norm(attr_matrix, ord=1, axis=1)\n",
        "        attr_invnorms = 1 / np.maximum(attr_norms, epsilon)\n",
        "        attr_mat_norm = attr_matrix * attr_invnorms[:, np.newaxis]\n",
        "    return attr_mat_norm\n",
        "\n",
        "\n",
        "def get_dataset(name: str, use_lcc: bool = True) -> InMemoryDataset:\n",
        "    dataset = InMemoryDataset\n",
        "    graph = load_dataset(name)\n",
        "    graph.standardize(select_lcc=True)\n",
        "    new_y = torch.LongTensor(graph.labels)\n",
        "    data = Data(\n",
        "            x=torch.FloatTensor(normalize_attributes(graph.attr_matrix).toarray()),\n",
        "            edge_index=torch.LongTensor(graph.get_edgeid_to_idx_array().T),\n",
        "            y=new_y,\n",
        "            train_mask=torch.zeros(new_y.size(0), dtype=torch.bool),\n",
        "            test_mask=torch.zeros(new_y.size(0), dtype=torch.bool),\n",
        "            val_mask=torch.zeros(new_y.size(0), dtype=torch.bool)\n",
        "        )\n",
        "    dataset.data = data\n",
        "    dataset.num_classes =len(np.unique(new_y))\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def set_train_val_test_split(\n",
        "        seed: int,\n",
        "        data: Data,\n",
        "        num_development: int = 1500,\n",
        "        num_per_class: int = 20) -> Data:\n",
        "    rnd_state = np.random.RandomState(development_seed)\n",
        "    num_nodes = data.y.shape[0]\n",
        "    development_idx = rnd_state.choice(num_nodes, num_development, replace=False)\n",
        "    test_idx = [i for i in np.arange(num_nodes) if i not in development_idx]\n",
        "\n",
        "    train_idx = []\n",
        "    rnd_state = np.random.RandomState(seed)\n",
        "    for c in range(data.y.max() + 1):\n",
        "        class_idx = development_idx[np.where(data.y[development_idx].cpu() == c)[0]]\n",
        "        train_idx.extend(rnd_state.choice(class_idx, num_per_class, replace=False))\n",
        "\n",
        "    val_idx_tmp = [i for i in development_idx if i not in train_idx]\n",
        "\n",
        "    val_idx = rnd_state.choice(val_idx_tmp, 500, replace=False)\n",
        "    def get_mask(idx):\n",
        "        mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "        mask[idx] = 1\n",
        "        return mask\n",
        "\n",
        "    data.train_mask = get_mask(train_idx)\n",
        "    data.val_mask = get_mask(val_idx)\n",
        "    data.test_mask = get_mask(test_idx)\n",
        "\n",
        "    return data\n",
        "\n"
      ],
      "metadata": {
        "id": "i2DVF7XHPIMN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Authors Utils:"
      ],
      "metadata": {
        "id": "n3FCngkZNyne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import yaml\n",
        "import torch\n",
        "import logging\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.sparse as sp\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import torch.nn.functional as F\n",
        "import seaborn as sns\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "from torch.optim import Adam, Optimizer\n",
        "from collections import defaultdict\n",
        "from torch_geometric.data import Data, InMemoryDataset\n",
        "\n",
        "\n",
        "def save_obj(obj, name):\n",
        "    with open('results/'+ name + '.pkl', 'wb') as f:\n",
        "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "def load_obj(name):\n",
        "    with open('results/' + name + '.pkl', 'rb') as f:\n",
        "        return pickle.load(f)\n",
        "\n",
        "def summary(results):\n",
        "    report={}\n",
        "    for k, v in results.items():\n",
        "        if k != 'steps' and k != 'probs':\n",
        "            boots_series = sns.algorithms.bootstrap(results[k], func=np.mean, n_boot=1000)\n",
        "            report[k] = np.mean(results[k])\n",
        "            report[f'{k}_ci'] = np.max(np.abs(sns.utils.ci(boots_series, 95) - report[k]))\n",
        "        else:\n",
        "            array = np.array([k.mean().cpu().detach().numpy() for k in results['steps']])\n",
        "            boots_series = sns.algorithms.bootstrap(array, func=np.mean, n_boot=1000)\n",
        "            report[k] = np.mean(array)\n",
        "            report[f'{k}_ci'] = np.max(np.abs(sns.utils.ci(boots_series, 95) - report[k]))\n",
        "    return report\n",
        "\n",
        "def plot_density(results):\n",
        "    fig, ax = plt.subplots()\n",
        "\n",
        "    z =[(x.cpu().numpy()).astype(int) for x in results['steps']]\n",
        "    z = np.vstack(z)\n",
        "    z = np.mean(z,axis=0)\n",
        "\n",
        "    sns.distplot(z, hist = False, kde = True,\n",
        "                 kde_kws = {'shade': True, 'linewidth': 3},\n",
        "                 ax=ax)\n",
        "    plt.xlabel('Number of Steps')\n",
        "    plt.ylabel('Density')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    return"
      ],
      "metadata": {
        "id": "UNlFDd9xNt5z"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Functions:"
      ],
      "metadata": {
        "id": "5HtQYu6zPcTA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model: torch.nn.Module, optimizer: Optimizer, data: Data, train_halt, weight_decay: float):\n",
        "    model.train()\n",
        "\n",
        "    for param in model.prop.parameters():\n",
        "        param.requires_grad = train_halt\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    logits, steps, reminders = model(data)\n",
        "\n",
        "    loss = F.nll_loss(logits[data.train_mask], data.y[data.train_mask])\n",
        "    l2_reg = sum((torch.sum(param ** 2) for param in model.reg_params))\n",
        "    loss += weight_decay/2 * l2_reg + model.prop_penalty *(\n",
        "            steps[data.train_mask] + reminders[data.train_mask]).mean()\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return\n",
        "\n",
        "def evaluate(model: torch.nn.Module, data: Data, test: bool, weight_decay: float):\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits, steps, reminders = model(data)\n",
        "\n",
        "        loss = F.nll_loss(logits[data.train_mask], data.y[data.train_mask])\n",
        "        l2_reg = sum((torch.sum(param ** 2) for param in model.reg_params))\n",
        "        loss += weight_decay/2 * l2_reg + model.prop_penalty *(\n",
        "                steps[data.train_mask] + reminders[data.train_mask]).mean()\n",
        "\n",
        "    eval_dict = {}\n",
        "    keys = ['train','val']\n",
        "    eval_dict['steps'] = steps\n",
        "    for key in keys:\n",
        "        mask = data[f'{key}_mask']\n",
        "        pred = logits[mask].max(1)[1]\n",
        "        acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n",
        "        eval_dict[f'{key}_acc'] = acc\n",
        "    return eval_dict, loss\n",
        "\n",
        "\n",
        "def test_acc(model: torch.nn.Module, data: Data):\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits, steps, reminders = model(data)\n",
        "    mask = data['test_mask']\n",
        "    pred = logits[mask].max(1)[1]\n",
        "    acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n",
        "    return acc"
      ],
      "metadata": {
        "id": "YlT1FBBNPZ5U"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run(dataset: InMemoryDataset,\n",
        "        model: torch.nn.Module,\n",
        "        seeds: np.ndarray,\n",
        "        test: bool = False,\n",
        "        max_epochs: int = 10000,\n",
        "        patience: int = 100,\n",
        "        lr: float = 0.01,\n",
        "        weight_decay: float = 0.01,\n",
        "        num_development: int = 1500,\n",
        "        device: str = 'cuda'):\n",
        "\n",
        "\n",
        "    best_dict = defaultdict(list)\n",
        "\n",
        "    for seed in tqdm(seeds):\n",
        "        for _ in range(config['niter_per_seed']):\n",
        "            torch_seed = gen_seeds()\n",
        "            torch.manual_seed(seed=torch_seed)\n",
        "\n",
        "            dataset.data = set_train_val_test_split(\n",
        "                seed,\n",
        "                dataset.data,\n",
        "                num_development=num_development,\n",
        "                num_per_class=20\n",
        "                ).to(device)\n",
        "\n",
        "            model.to(device).reset_parameters()\n",
        "            optimizer = Adam(model.parameters(),lr=lr)\n",
        "\n",
        "            patience_counter = 0\n",
        "            best_loss = 999\n",
        "            tmp_dict = {'val_acc': 0}\n",
        "\n",
        "            start_time = time.perf_counter()\n",
        "            for epoch in range(1, max_epochs + 1):\n",
        "                if patience_counter == patience:\n",
        "                    break\n",
        "\n",
        "                train(model, optimizer, dataset.data, epoch%5==0, weight_decay)\n",
        "                eval_dict, loss = evaluate(model, dataset.data, test, weight_decay)\n",
        "\n",
        "                if(eval_dict['val_acc'] > tmp_dict['val_acc']) or (\n",
        "                  (eval_dict['val_acc'] == tmp_dict['val_acc']) and loss < best_loss):\n",
        "                    patience_counter = 0\n",
        "                    tmp_dict['epoch'] = epoch\n",
        "                    tmp_dict['runtime'] = time.perf_counter() - start_time\n",
        "\n",
        "                    for k, v in eval_dict.items():\n",
        "                        tmp_dict[k] = v\n",
        "\n",
        "                    best_state = {key: value.cpu() for key, value\n",
        "                                      in model.state_dict().items()}\n",
        "\n",
        "                else:\n",
        "                    patience_counter += 1\n",
        "\n",
        "                if loss < best_loss:\n",
        "                    best_loss = loss\n",
        "                    patience_counter = 0\n",
        "\n",
        "            model.load_state_dict(best_state)\n",
        "            tmp_dict['test_acc'] = test_acc(model,dataset.data)\n",
        "            print(\"Epoch: {:.1f}\"\" Train: {:.2f}\"\" Val: {:.2f}\"\" Test: {:.2f}\".format(\n",
        "                  tmp_dict['epoch'],\n",
        "                  tmp_dict['train_acc'] * 100,\n",
        "                  tmp_dict['val_acc'] * 100,\n",
        "                  tmp_dict['test_acc'] * 100))\n",
        "\n",
        "            for k, v in tmp_dict.items():\n",
        "                best_dict[k].append(v)\n",
        "\n",
        "    return dict(best_dict)"
      ],
      "metadata": {
        "id": "nL5AoDsRPdjm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MxwNMsU7Pf7d"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RUN:"
      ],
      "metadata": {
        "id": "dt_BufFaPiXh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda'\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.synchronize()\n",
        "#Datasets: 'citeseer', 'cora_ml' 'pubmed' 'ms_academic', 'amazon_electronics_computers', 'amazon_electronics_photo'\n",
        "#Num Developent: 1500,1500,1500,5000,1500,1500\n",
        "# weight_decay 0 for Amazon Datasets 8e-03 for the others\n",
        "config = {'dataset_name': 'cora_ml',\n",
        "          'test': True,\n",
        "          'use_lcc': True,\n",
        "          'num_development': 1500,\n",
        "          'niter_per_seed': 5,\n",
        "          'hidden_units': 64,\n",
        "          'lr': 0.01,\n",
        "          'dropout': 0.5,\n",
        "          'weight_decay': 0\n",
        "         }\n",
        "\n",
        "dataset = get_dataset(\n",
        "    name=config['dataset_name'],\n",
        "    use_lcc=config['use_lcc']\n",
        "    )\n",
        "\n",
        "dataset.data = dataset.data.to(device)"
      ],
      "metadata": {
        "id": "97gMClIpPiyA"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WucbeVVPjH5",
        "outputId": "283c4ebc-4cc5-4da7-c952-dc072cdfb815"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(x=[2810, 2879], edge_index=[2, 15962], y=[2810], train_mask=[2810], test_mask=[2810], val_mask=[2810])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = APGCN(dataset,10, prop_penalty=0.05)\n",
        "\n",
        "total_params = sum(\n",
        "  param.numel() for param in model.parameters()\n",
        ")\n",
        "\n",
        "print(total_params)\n",
        "\n",
        "results = run(\n",
        "    dataset,\n",
        "    model,\n",
        "    seeds=test_seeds if config['test'] else val_seeds,\n",
        "    #seeds= quick_seeds,\n",
        "    lr=config['lr'],\n",
        "    weight_decay=config['weight_decay'],\n",
        "    test=config['test'],\n",
        "    num_development=config['num_development'],\n",
        "    device=device\n",
        "    )\n",
        "\n",
        "#save_obj(results,'results_' + config['dataset_name'])\n",
        "report = summary(results)\n",
        "\n",
        "print(\"FINAL\\n\"\n",
        "      \"Train Accuracy: {:.2f} ± {:.2f}%\\n\"\n",
        "      \"Stopping Accuracy: {:.2f} ± {:.2f}%\\n\"\n",
        "      \"Test     Accuracy: {:.2f} ± {:.2f}%\\n\"\n",
        "      \"Steps: {:.2f} ± {:.2f}\\n\"\n",
        "      \"Epochs:  {:.2f} ± {:.2f}\\n\"\n",
        "      \"Runtime: {:.4f} ± {:.4f}\\n\"\n",
        "      .format(\n",
        "          report['train_acc'] * 100,\n",
        "          report['train_acc_ci'] * 100,\n",
        "          report['val_acc'] * 100,\n",
        "          report['val_acc_ci'] * 100,\n",
        "          report['test_acc']*100,\n",
        "          report['test_acc_ci']*100,\n",
        "          report['steps'],\n",
        "          report['steps_ci'],\n",
        "          report['epoch'],\n",
        "          report['epoch_ci'],\n",
        "          report['runtime'],\n",
        "          report['runtime_ci']))\n",
        "\n",
        "plot_density(results)\n",
        "\n",
        "del model, dataset\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292,
          "referenced_widgets": [
            "887d797a43cb41dcaf1ac5b80ed98b5c",
            "0e8c885abadf48b5bfd0a7cb9acf09b6",
            "8dd2e26e7c194df980cb2b92064345f0",
            "401e794f805544f5891c315d5a6c4054",
            "1ce5f239d34444d98c3883200fce3e32",
            "2641b63114414e66abf26d294b1218d2",
            "acd92c141a5c4b36908943877ffe4ae1",
            "6e3da2a2077f4830a8ccbf58c33c968c",
            "0e227c6aa6304de1b97e58c75666dffb",
            "87c4622e2578446c98dd8dbd091c50a0",
            "26204dd39e624d0a88a069f8bef7ec0e"
          ]
        },
        "id": "ErmCjZ89pKEu",
        "outputId": "120a037c-1eec-4c28-9ff0-04707eda08d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "184783\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "887d797a43cb41dcaf1ac5b80ed98b5c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 66.0 Train: 99.29 Val: 80.00 Test: 80.46\n",
            "Epoch: 37.0 Train: 93.57 Val: 82.00 Test: 80.61\n",
            "Epoch: 132.0 Train: 100.00 Val: 82.00 Test: 81.98\n",
            "Epoch: 87.0 Train: 100.00 Val: 82.40 Test: 81.53\n",
            "Epoch: 88.0 Train: 100.00 Val: 80.60 Test: 80.46\n",
            "Epoch: 81.0 Train: 97.86 Val: 83.20 Test: 82.44\n",
            "Epoch: 57.0 Train: 96.43 Val: 82.80 Test: 84.43\n",
            "Epoch: 33.0 Train: 95.71 Val: 82.00 Test: 82.14\n",
            "Epoch: 52.0 Train: 97.14 Val: 81.80 Test: 82.06\n",
            "Epoch: 64.0 Train: 96.43 Val: 81.60 Test: 81.60\n",
            "Epoch: 70.0 Train: 99.29 Val: 84.20 Test: 85.04\n",
            "Epoch: 85.0 Train: 100.00 Val: 84.00 Test: 85.73\n",
            "Epoch: 104.0 Train: 99.29 Val: 83.80 Test: 85.65\n"
          ]
        }
      ]
    }
  ]
}